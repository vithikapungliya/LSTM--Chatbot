{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3491,"status":"ok","timestamp":1652598185910,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"},"user_tz":-330},"id":"EPQHd7KdZtIy","outputId":"404f69d3-c106-4132-d330-35b7049f0ff2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1qy2Su_cZ1Pg","executionInfo":{"status":"ok","timestamp":1652598185912,"user_tz":-330,"elapsed":13,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["import json \n","import matplotlib.pyplot as plt "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FGdbLr7eaAV3","executionInfo":{"status":"ok","timestamp":1652598186777,"user_tz":-330,"elapsed":876,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["path = '/content/drive/MyDrive/LSTM/ new_intents.json'\n","\n","with open(path) as file : \n","  data = json.load(file)\n","\n","\n","training_sentences = [] \n","training_labels = [] \n","labels = [] \n","responses = [] \n","\n","for intent in data['intents'] : \n","  for pattern in intent['patterns']:\n","    training_sentences.append(pattern) \n","    training_labels.append(intent['tag'])\n","  responses.append(intent['responses']) \n","\n","  labels.append(intent['tag'])\n","\n","num_classes = len(labels)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":884,"status":"ok","timestamp":1652598187655,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"},"user_tz":-330},"id":"LhZrbIpqaIOg","outputId":"e86ef754-ff22-431e-99a3-92e844034f3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(training_labels)\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"GqqauAg0ayTs","executionInfo":{"status":"ok","timestamp":1652598189790,"user_tz":-330,"elapsed":2140,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"C7w5R2c-b-DC","executionInfo":{"status":"ok","timestamp":1652598189790,"user_tz":-330,"elapsed":14,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["vocab_size = 1000 \n","embedding_dim = 32 \n","max_len = 20 \n","oov_token = \"<OOV>\"\n","\n","tokenizer = Tokenizer(num_words = vocab_size , oov_token = oov_token , lower = True , filters='!\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n' , split = ' ' )"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"p0kIrx8wd-gq","executionInfo":{"status":"ok","timestamp":1652598189791,"user_tz":-330,"elapsed":13,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["tokenizer.fit_on_texts(list(training_sentences)) "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Skw1WBP8eKdU","executionInfo":{"status":"ok","timestamp":1652598189791,"user_tz":-330,"elapsed":12,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["list_tokenized_train = tokenizer.texts_to_sequences(training_sentences)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"04Y6jgibeOJt","executionInfo":{"status":"ok","timestamp":1652598189792,"user_tz":-330,"elapsed":12,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["max_len = 10 \n","sequences = tokenizer.texts_to_sequences(training_sentences)\n","padded_sequences = pad_sequences(sequences, truncating='post', padding = 'post', maxlen=max_len)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"MP-YwTsFeSgG","executionInfo":{"status":"ok","timestamp":1652598189792,"user_tz":-330,"elapsed":11,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, onehot_encoded, test_size = 0.20, shuffle = True, stratify=onehot_encoded)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1652598189793,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"},"user_tz":-330},"id":"ZGzPka21gLgS","outputId":"86886120-a96e-43e9-849b-e32d0a8ea647"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dimensions :  (62, 10)\n","Test Dimensions :  (16, 10)\n"]}],"source":["print(\"Train Dimensions : \" ,X_train.shape)\n","print(\"Test Dimensions : \" ,X_test.shape)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kSlXTuLtglnd","executionInfo":{"status":"ok","timestamp":1652598189793,"user_tz":-330,"elapsed":8,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n","from keras.models import Model\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"iEUle1aOg59R","executionInfo":{"status":"ok","timestamp":1652598190883,"user_tz":-330,"elapsed":1098,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["#input layer \n","inp = Input(shape = (max_len , ))\n","max_features = vocab_size\n","#embedding layer\n","embed = embedding_dim\n","x = Embedding(max_features , embed , mask_zero = True)(inp)\n","#lstm layer \n","x = LSTM(64, return_sequences=True,name='lstm_layer')(x)\n","#max pooling for reducing dimensions \n","x = GlobalMaxPool1D()(x)\n","#dropout layer\n","x = Dropout(0.2)(x)\n","#Dense Layer \n","x = Dense(32, activation=\"relu\")(x)\n","x = Dense(16, activation=\"relu\")(x)\n","x = Dropout(0.2)(x)\n","#Output Layer\n","x = Dense(6, activation=\"softmax\")(x)\n","\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"HeK2jwWhiI8n","executionInfo":{"status":"ok","timestamp":1652598190885,"user_tz":-330,"elapsed":35,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["model = Model(inputs=inp, outputs=x)\n","model.compile(loss='categorical_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":764,"status":"ok","timestamp":1652598191617,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"},"user_tz":-330},"id":"uowh-HU4iR-j","outputId":"97901d99-fede-41a1-8b6b-21c51e6b14e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 10)]              0         \n","                                                                 \n"," embedding (Embedding)       (None, 10, 32)            32000     \n","                                                                 \n"," lstm_layer (LSTM)           (None, 10, 64)            24832     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 64)               0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 32)                2080      \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                528       \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 102       \n","                                                                 \n","=================================================================\n","Total params: 59,542\n","Trainable params: 59,542\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"3bWmuBssiTxf","executionInfo":{"status":"ok","timestamp":1652598191618,"user_tz":-330,"elapsed":32,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"k0yt3KA4jLg3","executionInfo":{"status":"ok","timestamp":1652598191619,"user_tz":-330,"elapsed":32,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["callback = EarlyStopping(monitor = 'val_loss' , patience = 10 , mode = 'min' )"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"UOAay9Uejnz2","executionInfo":{"status":"ok","timestamp":1652598191620,"user_tz":-330,"elapsed":32,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["filepath = '/content/drive/MyDrive/LSTM/bestv3.h5'\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode = 'max')\n","\n","callback_list = [checkpoint ]"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85588,"status":"ok","timestamp":1652598277177,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"},"user_tz":-330},"id":"MSR7HKyAllHI","outputId":"5a5c6e7a-5931-40ac-e93c-210b30011cbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","8/8 [==============================] - ETA: 0s - loss: 1.7912 - accuracy: 0.1452 \n","Epoch 1: val_accuracy improved from -inf to 0.31250, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 6s 240ms/step - loss: 1.7912 - accuracy: 0.1452 - val_loss: 1.7892 - val_accuracy: 0.3125\n","Epoch 2/500\n","7/8 [=========================>....] - ETA: 0s - loss: 1.7881 - accuracy: 0.2321\n","Epoch 2: val_accuracy improved from 0.31250 to 0.43750, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 0s 24ms/step - loss: 1.7875 - accuracy: 0.2419 - val_loss: 1.7867 - val_accuracy: 0.4375\n","Epoch 3/500\n","6/8 [=====================>........] - ETA: 0s - loss: 1.7831 - accuracy: 0.4167\n","Epoch 3: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 14ms/step - loss: 1.7819 - accuracy: 0.4032 - val_loss: 1.7820 - val_accuracy: 0.3750\n","Epoch 4/500\n","7/8 [=========================>....] - ETA: 0s - loss: 1.7736 - accuracy: 0.3929\n","Epoch 4: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 14ms/step - loss: 1.7715 - accuracy: 0.4355 - val_loss: 1.7751 - val_accuracy: 0.3750\n","Epoch 5/500\n","7/8 [=========================>....] - ETA: 0s - loss: 1.7612 - accuracy: 0.4821\n","Epoch 5: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 12ms/step - loss: 1.7589 - accuracy: 0.4839 - val_loss: 1.7639 - val_accuracy: 0.3125\n","Epoch 6/500\n","1/8 [==>...........................] - ETA: 0s - loss: 1.7323 - accuracy: 0.3750\n","Epoch 6: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 10ms/step - loss: 1.7395 - accuracy: 0.4355 - val_loss: 1.7451 - val_accuracy: 0.3750\n","Epoch 7/500\n","8/8 [==============================] - ETA: 0s - loss: 1.7007 - accuracy: 0.5000\n","Epoch 7: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 11ms/step - loss: 1.7007 - accuracy: 0.5000 - val_loss: 1.7054 - val_accuracy: 0.3750\n","Epoch 8/500\n","8/8 [==============================] - ETA: 0s - loss: 1.6355 - accuracy: 0.4516\n","Epoch 8: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 11ms/step - loss: 1.6355 - accuracy: 0.4516 - val_loss: 1.6267 - val_accuracy: 0.3125\n","Epoch 9/500\n","8/8 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 0.4194\n","Epoch 9: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 11ms/step - loss: 1.5316 - accuracy: 0.4194 - val_loss: 1.5559 - val_accuracy: 0.3750\n","Epoch 10/500\n","1/8 [==>...........................] - ETA: 0s - loss: 1.6064 - accuracy: 0.5000\n","Epoch 10: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 10ms/step - loss: 1.4696 - accuracy: 0.4194 - val_loss: 1.5006 - val_accuracy: 0.4375\n","Epoch 11/500\n","8/8 [==============================] - ETA: 0s - loss: 1.4138 - accuracy: 0.4677\n","Epoch 11: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 11ms/step - loss: 1.4138 - accuracy: 0.4677 - val_loss: 1.4332 - val_accuracy: 0.4375\n","Epoch 12/500\n","8/8 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 0.5806\n","Epoch 12: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 12ms/step - loss: 1.3020 - accuracy: 0.5806 - val_loss: 1.3750 - val_accuracy: 0.4375\n","Epoch 13/500\n","8/8 [==============================] - ETA: 0s - loss: 1.1891 - accuracy: 0.6129\n","Epoch 13: val_accuracy did not improve from 0.43750\n","8/8 [==============================] - 0s 12ms/step - loss: 1.1891 - accuracy: 0.6129 - val_loss: 1.3189 - val_accuracy: 0.4375\n","Epoch 14/500\n","8/8 [==============================] - ETA: 0s - loss: 1.2085 - accuracy: 0.5161\n","Epoch 14: val_accuracy improved from 0.43750 to 0.56250, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 0s 18ms/step - loss: 1.2085 - accuracy: 0.5161 - val_loss: 1.2517 - val_accuracy: 0.5625\n","Epoch 15/500\n","8/8 [==============================] - ETA: 0s - loss: 1.0796 - accuracy: 0.6452\n","Epoch 15: val_accuracy improved from 0.56250 to 0.68750, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 0s 20ms/step - loss: 1.0796 - accuracy: 0.6452 - val_loss: 1.2054 - val_accuracy: 0.6875\n","Epoch 16/500\n","8/8 [==============================] - ETA: 0s - loss: 0.9851 - accuracy: 0.6452\n","Epoch 16: val_accuracy did not improve from 0.68750\n","8/8 [==============================] - 0s 11ms/step - loss: 0.9851 - accuracy: 0.6452 - val_loss: 1.1561 - val_accuracy: 0.6875\n","Epoch 17/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.9433 - accuracy: 0.6786\n","Epoch 17: val_accuracy did not improve from 0.68750\n","8/8 [==============================] - 0s 14ms/step - loss: 0.9636 - accuracy: 0.6613 - val_loss: 1.0493 - val_accuracy: 0.6875\n","Epoch 18/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.6843 - accuracy: 0.6250\n","Epoch 18: val_accuracy did not improve from 0.68750\n","8/8 [==============================] - 0s 10ms/step - loss: 0.9418 - accuracy: 0.5645 - val_loss: 0.9897 - val_accuracy: 0.5625\n","Epoch 19/500\n","8/8 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.6613\n","Epoch 19: val_accuracy improved from 0.68750 to 0.75000, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 0s 19ms/step - loss: 0.8737 - accuracy: 0.6613 - val_loss: 0.9723 - val_accuracy: 0.7500\n","Epoch 20/500\n","8/8 [==============================] - ETA: 0s - loss: 0.7841 - accuracy: 0.7581\n","Epoch 20: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.7841 - accuracy: 0.7581 - val_loss: 0.9374 - val_accuracy: 0.6875\n","Epoch 21/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.5096 - accuracy: 0.6250\n","Epoch 21: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 9ms/step - loss: 0.7740 - accuracy: 0.6613 - val_loss: 0.9088 - val_accuracy: 0.6875\n","Epoch 22/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.9429 - accuracy: 0.6250\n","Epoch 22: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 9ms/step - loss: 0.7755 - accuracy: 0.6613 - val_loss: 0.8904 - val_accuracy: 0.6875\n","Epoch 23/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.6167 - accuracy: 0.7500\n","Epoch 23: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 10ms/step - loss: 0.8174 - accuracy: 0.6613 - val_loss: 0.8512 - val_accuracy: 0.6875\n","Epoch 24/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.5789 - accuracy: 0.7500\n","Epoch 24: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.7258 - val_loss: 0.8239 - val_accuracy: 0.7500\n","Epoch 25/500\n","8/8 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.6452\n","Epoch 25: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.6452 - val_loss: 0.9515 - val_accuracy: 0.6875\n","Epoch 26/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.5176 - accuracy: 0.7500\n","Epoch 26: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 10ms/step - loss: 0.7098 - accuracy: 0.7258 - val_loss: 0.8138 - val_accuracy: 0.7500\n","Epoch 27/500\n","1/8 [==>...........................] - ETA: 0s - loss: 1.0826 - accuracy: 0.5000\n","Epoch 27: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 9ms/step - loss: 0.6254 - accuracy: 0.7581 - val_loss: 0.7801 - val_accuracy: 0.7500\n","Epoch 28/500\n","8/8 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.7742\n","Epoch 28: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.6039 - accuracy: 0.7742 - val_loss: 0.8690 - val_accuracy: 0.7500\n","Epoch 29/500\n","8/8 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.7419\n","Epoch 29: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.5855 - accuracy: 0.7419 - val_loss: 0.8203 - val_accuracy: 0.7500\n","Epoch 30/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.6631 - accuracy: 0.6250\n","Epoch 30: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 10ms/step - loss: 0.5733 - accuracy: 0.7581 - val_loss: 0.7588 - val_accuracy: 0.7500\n","Epoch 31/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5539 - accuracy: 0.7321\n","Epoch 31: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 15ms/step - loss: 0.5404 - accuracy: 0.7419 - val_loss: 0.7664 - val_accuracy: 0.7500\n","Epoch 32/500\n","8/8 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.8548\n","Epoch 32: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.8548 - val_loss: 0.8110 - val_accuracy: 0.7500\n","Epoch 33/500\n","8/8 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.7258\n","Epoch 33: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 12ms/step - loss: 0.6031 - accuracy: 0.7258 - val_loss: 0.7830 - val_accuracy: 0.7500\n","Epoch 34/500\n","8/8 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.7742\n","Epoch 34: val_accuracy did not improve from 0.75000\n","8/8 [==============================] - 0s 11ms/step - loss: 0.5106 - accuracy: 0.7742 - val_loss: 0.7797 - val_accuracy: 0.7500\n","Epoch 35/500\n","8/8 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.8226\n","Epoch 35: val_accuracy improved from 0.75000 to 0.81250, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 0s 22ms/step - loss: 0.4882 - accuracy: 0.8226 - val_loss: 0.8094 - val_accuracy: 0.8125\n","Epoch 36/500\n","8/8 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7903\n","Epoch 36: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 11ms/step - loss: 0.5072 - accuracy: 0.7903 - val_loss: 0.7732 - val_accuracy: 0.8125\n","Epoch 37/500\n","8/8 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.7742\n","Epoch 37: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 12ms/step - loss: 0.4571 - accuracy: 0.7742 - val_loss: 0.7308 - val_accuracy: 0.8125\n","Epoch 38/500\n","8/8 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8387\n","Epoch 38: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 10ms/step - loss: 0.3667 - accuracy: 0.8387 - val_loss: 0.7354 - val_accuracy: 0.8125\n","Epoch 39/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.5945 - accuracy: 0.8750\n","Epoch 39: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 10ms/step - loss: 0.4177 - accuracy: 0.8387 - val_loss: 0.8192 - val_accuracy: 0.8125\n","Epoch 40/500\n","8/8 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.7581\n","Epoch 40: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 12ms/step - loss: 0.4735 - accuracy: 0.7581 - val_loss: 1.2534 - val_accuracy: 0.7500\n","Epoch 41/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4641 - accuracy: 0.8571\n","Epoch 41: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 12ms/step - loss: 0.4313 - accuracy: 0.8710 - val_loss: 0.7317 - val_accuracy: 0.8125\n","Epoch 42/500\n","8/8 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8387\n","Epoch 42: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 11ms/step - loss: 0.3879 - accuracy: 0.8387 - val_loss: 0.7257 - val_accuracy: 0.8125\n","Epoch 43/500\n","8/8 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8065\n","Epoch 43: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 11ms/step - loss: 0.3807 - accuracy: 0.8065 - val_loss: 0.8229 - val_accuracy: 0.8125\n","Epoch 44/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.9032\n","Epoch 44: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 11ms/step - loss: 0.2662 - accuracy: 0.9032 - val_loss: 0.8746 - val_accuracy: 0.8125\n","Epoch 45/500\n","8/8 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8871\n","Epoch 45: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 11ms/step - loss: 0.3339 - accuracy: 0.8871 - val_loss: 0.9168 - val_accuracy: 0.8125\n","Epoch 46/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9032\n","Epoch 46: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 12ms/step - loss: 0.2353 - accuracy: 0.9032 - val_loss: 0.8605 - val_accuracy: 0.8125\n","Epoch 47/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2560 - accuracy: 0.9286\n","Epoch 47: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 13ms/step - loss: 0.2781 - accuracy: 0.9194 - val_loss: 0.8180 - val_accuracy: 0.8125\n","Epoch 48/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.8710\n","Epoch 48: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 12ms/step - loss: 0.2919 - accuracy: 0.8710 - val_loss: 0.9126 - val_accuracy: 0.8125\n","Epoch 49/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1830 - accuracy: 0.9821\n","Epoch 49: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 13ms/step - loss: 0.1827 - accuracy: 0.9677 - val_loss: 1.0032 - val_accuracy: 0.7500\n","Epoch 50/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9194\n","Epoch 50: val_accuracy did not improve from 0.81250\n","8/8 [==============================] - 0s 11ms/step - loss: 0.2412 - accuracy: 0.9194 - val_loss: 0.9412 - val_accuracy: 0.8125\n","Epoch 51/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1745 - accuracy: 0.9643\n","Epoch 51: val_accuracy improved from 0.81250 to 0.87500, saving model to /content/drive/MyDrive/LSTM/bestv3.h5\n","8/8 [==============================] - 0s 19ms/step - loss: 0.2144 - accuracy: 0.9355 - val_loss: 0.8917 - val_accuracy: 0.8750\n","Epoch 52/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9194\n","Epoch 52: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.2514 - accuracy: 0.9194 - val_loss: 0.8401 - val_accuracy: 0.8750\n","Epoch 53/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1312 - accuracy: 0.9821\n","Epoch 53: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.1367 - accuracy: 0.9839 - val_loss: 0.8073 - val_accuracy: 0.8750\n","Epoch 54/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.9194\n","Epoch 54: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.2138 - accuracy: 0.9194 - val_loss: 0.7443 - val_accuracy: 0.8750\n","Epoch 55/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.9516\n","Epoch 55: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9516 - val_loss: 1.3046 - val_accuracy: 0.7500\n","Epoch 56/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.9194\n","Epoch 56: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1955 - accuracy: 0.9194 - val_loss: 1.5217 - val_accuracy: 0.7500\n","Epoch 57/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.9032\n","Epoch 57: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.2134 - accuracy: 0.9032 - val_loss: 1.1933 - val_accuracy: 0.7500\n","Epoch 58/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.9677\n","Epoch 58: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1606 - accuracy: 0.9677 - val_loss: 1.0447 - val_accuracy: 0.8125\n","Epoch 59/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9516\n","Epoch 59: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1321 - accuracy: 0.9516 - val_loss: 1.1517 - val_accuracy: 0.8125\n","Epoch 60/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.9677\n","Epoch 60: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1740 - accuracy: 0.9677 - val_loss: 1.1065 - val_accuracy: 0.8125\n","Epoch 61/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9677\n","Epoch 61: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1121 - accuracy: 0.9677 - val_loss: 0.8702 - val_accuracy: 0.8750\n","Epoch 62/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9839\n","Epoch 62: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1148 - accuracy: 0.9839 - val_loss: 0.8751 - val_accuracy: 0.8750\n","Epoch 63/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9677\n","Epoch 63: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1064 - accuracy: 0.9677 - val_loss: 0.8532 - val_accuracy: 0.8750\n","Epoch 64/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9839\n","Epoch 64: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1137 - accuracy: 0.9839 - val_loss: 0.8719 - val_accuracy: 0.8750\n","Epoch 65/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9839\n","Epoch 65: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0942 - accuracy: 0.9839 - val_loss: 0.9956 - val_accuracy: 0.8750\n","Epoch 66/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n","Epoch 66: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.8125\n","Epoch 67/500\n","8/8 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9032\n","Epoch 67: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.2198 - accuracy: 0.9032 - val_loss: 0.9273 - val_accuracy: 0.8750\n","Epoch 68/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9839\n","Epoch 68: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0938 - accuracy: 0.9839 - val_loss: 0.8708 - val_accuracy: 0.8750\n","Epoch 69/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9677\n","Epoch 69: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1169 - accuracy: 0.9677 - val_loss: 1.2863 - val_accuracy: 0.8125\n","Epoch 70/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9839\n","Epoch 70: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0924 - accuracy: 0.9839 - val_loss: 1.5180 - val_accuracy: 0.8125\n","Epoch 71/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0372 - accuracy: 1.0000\n","Epoch 71: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0704 - accuracy: 0.9839 - val_loss: 1.5102 - val_accuracy: 0.8125\n","Epoch 72/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 72: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 10ms/step - loss: 0.0815 - accuracy: 0.9677 - val_loss: 1.3725 - val_accuracy: 0.8125\n","Epoch 73/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9677\n","Epoch 73: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9677 - val_loss: 1.3603 - val_accuracy: 0.8125\n","Epoch 74/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9516\n","Epoch 74: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9516 - val_loss: 1.6636 - val_accuracy: 0.8125\n","Epoch 75/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 1.0000\n","Epoch 75: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 1.8735 - val_accuracy: 0.8125\n","Epoch 76/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9516\n","Epoch 76: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0796 - accuracy: 0.9516 - val_loss: 1.8940 - val_accuracy: 0.8125\n","Epoch 77/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9677\n","Epoch 77: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9677 - val_loss: 1.7891 - val_accuracy: 0.8125\n","Epoch 78/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9677\n","Epoch 78: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0904 - accuracy: 0.9677 - val_loss: 1.6367 - val_accuracy: 0.8125\n","Epoch 79/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9516\n","Epoch 79: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0996 - accuracy: 0.9516 - val_loss: 1.2228 - val_accuracy: 0.8125\n","Epoch 80/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9677\n","Epoch 80: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1070 - accuracy: 0.9677 - val_loss: 1.1495 - val_accuracy: 0.8750\n","Epoch 81/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000\n","Epoch 81: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1077 - accuracy: 0.9516 - val_loss: 1.6008 - val_accuracy: 0.8125\n","Epoch 82/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9516\n","Epoch 82: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9516 - val_loss: 2.1951 - val_accuracy: 0.8125\n","Epoch 83/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9677\n","Epoch 83: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9677 - val_loss: 0.9433 - val_accuracy: 0.8750\n","Epoch 84/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9677\n","Epoch 84: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1554 - accuracy: 0.9677 - val_loss: 3.3367 - val_accuracy: 0.6875\n","Epoch 85/500\n","8/8 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.9355\n","Epoch 85: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.3732 - accuracy: 0.9355 - val_loss: 2.7425 - val_accuracy: 0.6875\n","Epoch 86/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 1.0000\n","Epoch 86: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 1.9540 - val_accuracy: 0.7500\n","Epoch 87/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9839\n","Epoch 87: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0995 - accuracy: 0.9839 - val_loss: 1.9223 - val_accuracy: 0.7500\n","Epoch 88/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.9194\n","Epoch 88: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1965 - accuracy: 0.9194 - val_loss: 1.6860 - val_accuracy: 0.8125\n","Epoch 89/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0996 - accuracy: 0.9821\n","Epoch 89: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1007 - accuracy: 0.9839 - val_loss: 1.5027 - val_accuracy: 0.8125\n","Epoch 90/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9516\n","Epoch 90: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1172 - accuracy: 0.9516 - val_loss: 1.4263 - val_accuracy: 0.8125\n","Epoch 91/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 1.0000\n","Epoch 91: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.8125\n","Epoch 92/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2637 - accuracy: 0.9464\n","Epoch 92: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.2391 - accuracy: 0.9516 - val_loss: 1.5306 - val_accuracy: 0.7500\n","Epoch 93/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 1.0000\n","Epoch 93: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 2.2683 - val_accuracy: 0.6250\n","Epoch 94/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9677\n","Epoch 94: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1027 - accuracy: 0.9677 - val_loss: 2.7017 - val_accuracy: 0.6250\n","Epoch 95/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9839\n","Epoch 95: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9839 - val_loss: 2.8876 - val_accuracy: 0.6875\n","Epoch 96/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9839\n","Epoch 96: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0569 - accuracy: 0.9839 - val_loss: 2.9796 - val_accuracy: 0.6875\n","Epoch 97/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.0517 - accuracy: 1.0000\n","Epoch 97: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9839 - val_loss: 3.0310 - val_accuracy: 0.6875\n","Epoch 98/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9839\n","Epoch 98: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0733 - accuracy: 0.9839 - val_loss: 3.0198 - val_accuracy: 0.6875\n","Epoch 99/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000\n","Epoch 99: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 3.0107 - val_accuracy: 0.6875\n","Epoch 100/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0498 - accuracy: 0.9821\n","Epoch 100: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0459 - accuracy: 0.9839 - val_loss: 2.8618 - val_accuracy: 0.6875\n","Epoch 101/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9821\n","Epoch 101: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 2.6981 - val_accuracy: 0.6875\n","Epoch 102/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0620 - accuracy: 0.9821\n","Epoch 102: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0587 - accuracy: 0.9839 - val_loss: 2.6114 - val_accuracy: 0.6875\n","Epoch 103/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9839\n","Epoch 103: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9839 - val_loss: 2.5481 - val_accuracy: 0.6875\n","Epoch 104/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0697 - accuracy: 0.9792\n","Epoch 104: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9677 - val_loss: 2.4825 - val_accuracy: 0.6875\n","Epoch 105/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9516\n","Epoch 105: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.1086 - accuracy: 0.9516 - val_loss: 2.4056 - val_accuracy: 0.6875\n","Epoch 106/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9839\n","Epoch 106: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0488 - accuracy: 0.9839 - val_loss: 2.3824 - val_accuracy: 0.6875\n","Epoch 107/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0734 - accuracy: 0.9643\n","Epoch 107: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0703 - accuracy: 0.9677 - val_loss: 2.3051 - val_accuracy: 0.6875\n","Epoch 108/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0494 - accuracy: 0.9821\n","Epoch 108: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0472 - accuracy: 0.9839 - val_loss: 2.2661 - val_accuracy: 0.6875\n","Epoch 109/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n","Epoch 109: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.2410 - val_accuracy: 0.6875\n","Epoch 110/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0349 - accuracy: 1.0000\n","Epoch 110: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 2.4749 - val_accuracy: 0.6875\n","Epoch 111/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.0000\n","Epoch 111: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 2.6246 - val_accuracy: 0.6875\n","Epoch 112/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0461 - accuracy: 0.9821\n","Epoch 112: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0449 - accuracy: 0.9839 - val_loss: 2.7079 - val_accuracy: 0.6875\n","Epoch 113/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0919 - accuracy: 0.9821\n","Epoch 113: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0831 - accuracy: 0.9839 - val_loss: 2.6695 - val_accuracy: 0.6875\n","Epoch 114/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9677\n","Epoch 114: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9677 - val_loss: 2.6755 - val_accuracy: 0.6875\n","Epoch 115/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.0000\n","Epoch 115: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 2.6952 - val_accuracy: 0.6875\n","Epoch 116/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9839\n","Epoch 116: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.1008 - accuracy: 0.9839 - val_loss: 2.6782 - val_accuracy: 0.6875\n","Epoch 117/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000\n","Epoch 117: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 2.6175 - val_accuracy: 0.6875\n","Epoch 118/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0681 - accuracy: 0.9643\n","Epoch 118: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0623 - accuracy: 0.9677 - val_loss: 2.6435 - val_accuracy: 0.6875\n","Epoch 119/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0872 - accuracy: 0.9643\n","Epoch 119: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0813 - accuracy: 0.9677 - val_loss: 2.7254 - val_accuracy: 0.6875\n","Epoch 120/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0435 - accuracy: 0.9821\n","Epoch 120: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 2.7414 - val_accuracy: 0.6875\n","Epoch 121/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0365 - accuracy: 1.0000\n","Epoch 121: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 2.6836 - val_accuracy: 0.6875\n","Epoch 122/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9839\n","Epoch 122: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9839 - val_loss: 2.6142 - val_accuracy: 0.6875\n","Epoch 123/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\n","Epoch 123: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.5744 - val_accuracy: 0.6875\n","Epoch 124/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 1.0000\n","Epoch 124: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 2.5666 - val_accuracy: 0.6875\n","Epoch 125/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0649 - accuracy: 0.9643\n","Epoch 125: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0595 - accuracy: 0.9677 - val_loss: 2.4643 - val_accuracy: 0.6875\n","Epoch 126/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9839\n","Epoch 126: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 2.4351 - val_accuracy: 0.6875\n","Epoch 127/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\n","Epoch 127: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.4467 - val_accuracy: 0.6250\n","Epoch 128/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 1.0000\n","Epoch 128: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 2.4822 - val_accuracy: 0.6250\n","Epoch 129/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9839\n","Epoch 129: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0874 - accuracy: 0.9839 - val_loss: 2.5813 - val_accuracy: 0.6250\n","Epoch 130/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.0000\n","Epoch 130: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.6430 - val_accuracy: 0.6250\n","Epoch 131/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.0000\n","Epoch 131: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.6707 - val_accuracy: 0.6250\n","Epoch 132/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0355 - accuracy: 1.0000\n","Epoch 132: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 2.6721 - val_accuracy: 0.6250\n","Epoch 133/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9839    \n","Epoch 133: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0487 - accuracy: 0.9839 - val_loss: 2.6492 - val_accuracy: 0.6250\n","Epoch 134/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n","Epoch 134: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.6117 - val_accuracy: 0.6250\n","Epoch 135/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9839\n","Epoch 135: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0450 - accuracy: 0.9839 - val_loss: 2.5957 - val_accuracy: 0.6250\n","Epoch 136/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0464 - accuracy: 1.0000\n","Epoch 136: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 2.6310 - val_accuracy: 0.6250\n","Epoch 137/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9839\n","Epoch 137: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9839 - val_loss: 2.6829 - val_accuracy: 0.6250\n","Epoch 138/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 1.0000\n","Epoch 138: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 2.7103 - val_accuracy: 0.6250\n","Epoch 139/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000\n","Epoch 139: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.6948 - val_accuracy: 0.6250\n","Epoch 140/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0273 - accuracy: 1.0000\n","Epoch 140: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 18ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.6934 - val_accuracy: 0.6250\n","Epoch 141/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0987 - accuracy: 0.9464\n","Epoch 141: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9516 - val_loss: 2.6987 - val_accuracy: 0.6875\n","Epoch 142/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0337 - accuracy: 1.0000    \n","Epoch 142: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0706 - accuracy: 0.9839 - val_loss: 2.7310 - val_accuracy: 0.6875\n","Epoch 143/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000\n","Epoch 143: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.7768 - val_accuracy: 0.6875\n","Epoch 144/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9677\n","Epoch 144: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0662 - accuracy: 0.9677 - val_loss: 2.7807 - val_accuracy: 0.6875\n","Epoch 145/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9821\n","Epoch 145: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9839 - val_loss: 2.7303 - val_accuracy: 0.6875\n","Epoch 146/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000\n","Epoch 146: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.7463 - val_accuracy: 0.6875\n","Epoch 147/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 147: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7691 - val_accuracy: 0.6875\n","Epoch 148/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0546 - accuracy: 0.9821\n","Epoch 148: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 2.7935 - val_accuracy: 0.6875\n","Epoch 149/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0578 - accuracy: 0.9821\n","Epoch 149: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9839 - val_loss: 2.7532 - val_accuracy: 0.6875\n","Epoch 150/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0360 - accuracy: 0.9821\n","Epoch 150: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0378 - accuracy: 0.9839 - val_loss: 2.5766 - val_accuracy: 0.6875\n","Epoch 151/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 1.0000\n","Epoch 151: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 2.5073 - val_accuracy: 0.6875\n","Epoch 152/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n","Epoch 152: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5738 - val_accuracy: 0.6875\n","Epoch 153/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9677\n","Epoch 153: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0570 - accuracy: 0.9677 - val_loss: 2.6641 - val_accuracy: 0.6875\n","Epoch 154/500\n","8/8 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9355\n","Epoch 154: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.1087 - accuracy: 0.9355 - val_loss: 2.6454 - val_accuracy: 0.6875\n","Epoch 155/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9839\n","Epoch 155: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 2.7201 - val_accuracy: 0.6875\n","Epoch 156/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0799 - accuracy: 0.9821    \n","Epoch 156: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9839 - val_loss: 2.7760 - val_accuracy: 0.6875\n","Epoch 157/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000\n","Epoch 157: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.6875\n","Epoch 158/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000    \n","Epoch 158: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8183 - val_accuracy: 0.6875\n","Epoch 159/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000\n","Epoch 159: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.8213 - val_accuracy: 0.6875\n","Epoch 160/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0415 - accuracy: 0.9792\n","Epoch 160: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0515 - accuracy: 0.9677 - val_loss: 2.7911 - val_accuracy: 0.6875\n","Epoch 161/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9821\n","Epoch 161: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 0.9839 - val_loss: 2.7153 - val_accuracy: 0.6875\n","Epoch 162/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0614 - accuracy: 0.9375\n","Epoch 162: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0668 - accuracy: 0.9355 - val_loss: 2.6242 - val_accuracy: 0.6875\n","Epoch 163/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0815 - accuracy: 0.9643\n","Epoch 163: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0755 - accuracy: 0.9677 - val_loss: 2.5451 - val_accuracy: 0.6875\n","Epoch 164/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0198 - accuracy: 1.0000\n","Epoch 164: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.5141 - val_accuracy: 0.6875\n","Epoch 165/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0397 - accuracy: 0.9821\n","Epoch 165: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0361 - accuracy: 0.9839 - val_loss: 2.5235 - val_accuracy: 0.6875\n","Epoch 166/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n","Epoch 166: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.5813 - val_accuracy: 0.6875\n","Epoch 167/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 167: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6374 - val_accuracy: 0.6875\n","Epoch 168/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0435 - accuracy: 0.9821\n","Epoch 168: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0393 - accuracy: 0.9839 - val_loss: 2.6696 - val_accuracy: 0.6875\n","Epoch 169/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0287 - accuracy: 0.9821\n","Epoch 169: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.9839 - val_loss: 2.5969 - val_accuracy: 0.6875\n","Epoch 170/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0395 - accuracy: 1.0000\n","Epoch 170: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0664 - accuracy: 0.9839 - val_loss: 2.5781 - val_accuracy: 0.6875\n","Epoch 171/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n","Epoch 171: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.7500\n","Epoch 172/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0576 - accuracy: 0.9821\n","Epoch 172: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 2.6282 - val_accuracy: 0.6875\n","Epoch 173/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9839\n","Epoch 173: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9839 - val_loss: 2.7433 - val_accuracy: 0.6250\n","Epoch 174/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 1.0000\n","Epoch 174: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 2.8855 - val_accuracy: 0.6250\n","Epoch 175/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0329 - accuracy: 0.9821\n","Epoch 175: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9839 - val_loss: 2.9913 - val_accuracy: 0.6875\n","Epoch 176/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0317 - accuracy: 0.9821\n","Epoch 176: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0571 - accuracy: 0.9677 - val_loss: 3.1831 - val_accuracy: 0.6875\n","Epoch 177/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0779 - accuracy: 0.9643\n","Epoch 177: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0762 - accuracy: 0.9677 - val_loss: 3.2829 - val_accuracy: 0.6250\n","Epoch 178/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0644 - accuracy: 0.9643\n","Epoch 178: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0874 - accuracy: 0.9516 - val_loss: 3.2460 - val_accuracy: 0.6875\n","Epoch 179/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n","Epoch 179: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 3.1713 - val_accuracy: 0.6875\n","Epoch 180/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0390 - accuracy: 0.9821\n","Epoch 180: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 3.1016 - val_accuracy: 0.6875\n","Epoch 181/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0781 - accuracy: 0.9792\n","Epoch 181: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9839 - val_loss: 2.6605 - val_accuracy: 0.6875\n","Epoch 182/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0188 - accuracy: 1.0000\n","Epoch 182: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.4864 - val_accuracy: 0.6875\n","Epoch 183/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0595 - accuracy: 0.9821\n","Epoch 183: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0539 - accuracy: 0.9839 - val_loss: 2.4008 - val_accuracy: 0.6875\n","Epoch 184/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n","Epoch 184: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3598 - val_accuracy: 0.6875\n","Epoch 185/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000    \n","Epoch 185: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.3546 - val_accuracy: 0.6875\n","Epoch 186/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0347 - accuracy: 0.9821\n","Epoch 186: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0325 - accuracy: 0.9839 - val_loss: 2.4271 - val_accuracy: 0.6875\n","Epoch 187/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0678 - accuracy: 0.9821\n","Epoch 187: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0623 - accuracy: 0.9839 - val_loss: 2.4646 - val_accuracy: 0.6875\n","Epoch 188/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0429 - accuracy: 0.9821\n","Epoch 188: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9839 - val_loss: 2.4438 - val_accuracy: 0.6875\n","Epoch 189/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9677\n","Epoch 189: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0719 - accuracy: 0.9677 - val_loss: 2.3577 - val_accuracy: 0.6875\n","Epoch 190/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000\n","Epoch 190: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.3205 - val_accuracy: 0.6875\n","Epoch 191/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n","Epoch 191: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.3095 - val_accuracy: 0.6250\n","Epoch 192/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n","Epoch 192: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.2962 - val_accuracy: 0.6875\n","Epoch 193/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9839\n","Epoch 193: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9839 - val_loss: 2.2672 - val_accuracy: 0.6875\n","Epoch 194/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0443 - accuracy: 0.9792\n","Epoch 194: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9839 - val_loss: 2.2592 - val_accuracy: 0.6875\n","Epoch 195/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n","Epoch 195: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2598 - val_accuracy: 0.6875\n","Epoch 196/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9643\n","Epoch 196: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0506 - accuracy: 0.9677 - val_loss: 2.2762 - val_accuracy: 0.6875\n","Epoch 197/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0477 - accuracy: 0.9821\n","Epoch 197: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0431 - accuracy: 0.9839 - val_loss: 2.2798 - val_accuracy: 0.6875\n","Epoch 198/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n","Epoch 198: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.2775 - val_accuracy: 0.6875\n","Epoch 199/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0381 - accuracy: 0.9792\n","Epoch 199: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9839 - val_loss: 2.2402 - val_accuracy: 0.6875\n","Epoch 200/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 200: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.2279 - val_accuracy: 0.6875\n","Epoch 201/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0532 - accuracy: 0.9643    \n","Epoch 201: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0520 - accuracy: 0.9677 - val_loss: 2.2024 - val_accuracy: 0.6875\n","Epoch 202/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0366 - accuracy: 0.9821\n","Epoch 202: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 0.9839 - val_loss: 2.2067 - val_accuracy: 0.6875\n","Epoch 203/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n","Epoch 203: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.2696 - val_accuracy: 0.6875\n","Epoch 204/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9839\n","Epoch 204: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 2.3190 - val_accuracy: 0.6875\n","Epoch 205/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0706 - accuracy: 0.9821\n","Epoch 205: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0657 - accuracy: 0.9839 - val_loss: 2.3240 - val_accuracy: 0.6875\n","Epoch 206/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000\n","Epoch 206: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.3635 - val_accuracy: 0.6875\n","Epoch 207/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0761 - accuracy: 0.9821\n","Epoch 207: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0738 - accuracy: 0.9839 - val_loss: 2.3934 - val_accuracy: 0.6875\n","Epoch 208/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9839\n","Epoch 208: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9839 - val_loss: 2.4227 - val_accuracy: 0.6875\n","Epoch 209/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0703 - accuracy: 0.9643\n","Epoch 209: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0642 - accuracy: 0.9677 - val_loss: 2.3786 - val_accuracy: 0.7500\n","Epoch 210/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n","Epoch 210: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.3154 - val_accuracy: 0.7500\n","Epoch 211/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000\n","Epoch 211: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.2402 - val_accuracy: 0.7500\n","Epoch 212/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000    \n","Epoch 212: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.2075 - val_accuracy: 0.7500\n","Epoch 213/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0179 - accuracy: 0.9821    \n","Epoch 213: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9839 - val_loss: 2.1894 - val_accuracy: 0.7500\n","Epoch 214/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n","Epoch 214: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1645 - val_accuracy: 0.7500\n","Epoch 215/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000    \n","Epoch 215: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.1838 - val_accuracy: 0.6875\n","Epoch 216/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000\n","Epoch 216: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 2.2222 - val_accuracy: 0.6875\n","Epoch 217/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000    \n","Epoch 217: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.2366 - val_accuracy: 0.6875\n","Epoch 218/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9839\n","Epoch 218: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0421 - accuracy: 0.9839 - val_loss: 2.4129 - val_accuracy: 0.6875\n","Epoch 219/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0233 - accuracy: 0.9821\n","Epoch 219: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9839 - val_loss: 2.5437 - val_accuracy: 0.6875\n","Epoch 220/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0394 - accuracy: 0.9821\n","Epoch 220: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0386 - accuracy: 0.9839 - val_loss: 2.6022 - val_accuracy: 0.6875\n","Epoch 221/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 221: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6438 - val_accuracy: 0.6875\n","Epoch 222/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9677\n","Epoch 222: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 25ms/step - loss: 0.0579 - accuracy: 0.9677 - val_loss: 2.5591 - val_accuracy: 0.6875\n","Epoch 223/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0201 - accuracy: 0.9792    \n","Epoch 223: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.9839 - val_loss: 2.4699 - val_accuracy: 0.6875\n","Epoch 224/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0806 - accuracy: 0.9583\n","Epoch 224: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0628 - accuracy: 0.9677 - val_loss: 2.8150 - val_accuracy: 0.6875\n","Epoch 225/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000    \n","Epoch 225: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 3.0324 - val_accuracy: 0.6875\n","Epoch 226/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\n","Epoch 226: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 3.2436 - val_accuracy: 0.6875\n","Epoch 227/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9839    \n","Epoch 227: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0556 - accuracy: 0.9839 - val_loss: 3.3973 - val_accuracy: 0.6875\n","Epoch 228/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9839\n","Epoch 228: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9839 - val_loss: 3.4522 - val_accuracy: 0.6250\n","Epoch 229/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9677\n","Epoch 229: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0435 - accuracy: 0.9677 - val_loss: 3.4923 - val_accuracy: 0.6250\n","Epoch 230/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.0000    \n","Epoch 230: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 3.5212 - val_accuracy: 0.6875\n","Epoch 231/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1121 - accuracy: 0.9821\n","Epoch 231: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.1021 - accuracy: 0.9839 - val_loss: 3.4771 - val_accuracy: 0.6875\n","Epoch 232/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000\n","Epoch 232: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 3.4320 - val_accuracy: 0.6875\n","Epoch 233/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n","Epoch 233: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.3957 - val_accuracy: 0.6875\n","Epoch 234/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000    \n","Epoch 234: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 3.3641 - val_accuracy: 0.6875\n","Epoch 235/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0841 - accuracy: 0.9583\n","Epoch 235: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0665 - accuracy: 0.9677 - val_loss: 3.3825 - val_accuracy: 0.6875\n","Epoch 236/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000\n","Epoch 236: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 3.3934 - val_accuracy: 0.6875\n","Epoch 237/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n","Epoch 237: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.3972 - val_accuracy: 0.6875\n","Epoch 238/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9839\n","Epoch 238: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9839 - val_loss: 3.3471 - val_accuracy: 0.6875\n","Epoch 239/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\n","Epoch 239: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.3060 - val_accuracy: 0.6875\n","Epoch 240/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n","Epoch 240: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 3.1754 - val_accuracy: 0.6875\n","Epoch 241/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000    \n","Epoch 241: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.1023 - val_accuracy: 0.6875\n","Epoch 242/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9839\n","Epoch 242: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9839 - val_loss: 3.1330 - val_accuracy: 0.6250\n","Epoch 243/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9839    \n","Epoch 243: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 0.9839 - val_loss: 3.1931 - val_accuracy: 0.6250\n","Epoch 244/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n","Epoch 244: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.2421 - val_accuracy: 0.6250\n","Epoch 245/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0426 - accuracy: 0.9821\n","Epoch 245: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0393 - accuracy: 0.9839 - val_loss: 3.3150 - val_accuracy: 0.6250\n","Epoch 246/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0430 - accuracy: 0.9821    \n","Epoch 246: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9839 - val_loss: 3.3135 - val_accuracy: 0.6250\n","Epoch 247/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n","Epoch 247: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.3023 - val_accuracy: 0.6250\n","Epoch 248/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0293 - accuracy: 0.9821    \n","Epoch 248: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0270 - accuracy: 0.9839 - val_loss: 3.2530 - val_accuracy: 0.6250\n","Epoch 249/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000    \n","Epoch 249: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 3.1685 - val_accuracy: 0.6250\n","Epoch 250/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9839    \n","Epoch 250: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0696 - accuracy: 0.9839 - val_loss: 2.9907 - val_accuracy: 0.6250\n","Epoch 251/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000    \n","Epoch 251: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.9253 - val_accuracy: 0.6250\n","Epoch 252/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000    \n","Epoch 252: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9375 - val_accuracy: 0.6250\n","Epoch 253/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9839\n","Epoch 253: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9839 - val_loss: 2.9583 - val_accuracy: 0.5625\n","Epoch 254/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000    \n","Epoch 254: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.9420 - val_accuracy: 0.5625\n","Epoch 255/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0376 - accuracy: 0.9821\n","Epoch 255: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0340 - accuracy: 0.9839 - val_loss: 2.9434 - val_accuracy: 0.5625\n","Epoch 256/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0809 - accuracy: 0.9464\n","Epoch 256: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0731 - accuracy: 0.9516 - val_loss: 2.8818 - val_accuracy: 0.6250\n","Epoch 257/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000    \n","Epoch 257: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.9277 - val_accuracy: 0.6250\n","Epoch 258/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000\n","Epoch 258: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 18ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 3.0124 - val_accuracy: 0.5625\n","Epoch 259/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0409 - accuracy: 0.9792    \n","Epoch 259: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0452 - accuracy: 0.9839 - val_loss: 3.0762 - val_accuracy: 0.5625\n","Epoch 260/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0291 - accuracy: 0.9821\n","Epoch 260: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0268 - accuracy: 0.9839 - val_loss: 3.2155 - val_accuracy: 0.6250\n","Epoch 261/500\n","1/8 [==>...........................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 261: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 10ms/step - loss: 0.0300 - accuracy: 0.9839 - val_loss: 3.2116 - val_accuracy: 0.6875\n","Epoch 262/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0267 - accuracy: 1.0000\n","Epoch 262: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 3.0842 - val_accuracy: 0.6875\n","Epoch 263/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9839\n","Epoch 263: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0359 - accuracy: 0.9839 - val_loss: 2.9623 - val_accuracy: 0.6875\n","Epoch 264/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000\n","Epoch 264: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.8497 - val_accuracy: 0.6875\n","Epoch 265/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0951 - accuracy: 0.9643\n","Epoch 265: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0860 - accuracy: 0.9677 - val_loss: 2.8684 - val_accuracy: 0.6875\n","Epoch 266/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0527 - accuracy: 0.9792\n","Epoch 266: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 2.8773 - val_accuracy: 0.6875\n","Epoch 267/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000    \n","Epoch 267: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.8486 - val_accuracy: 0.6250\n","Epoch 268/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 268: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.8932 - val_accuracy: 0.6250\n","Epoch 269/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0567 - accuracy: 0.9821\n","Epoch 269: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 2.8184 - val_accuracy: 0.6250\n","Epoch 270/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0564 - accuracy: 0.9821\n","Epoch 270: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0510 - accuracy: 0.9839 - val_loss: 2.5697 - val_accuracy: 0.6250\n","Epoch 271/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000    \n","Epoch 271: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0415 - accuracy: 0.9839 - val_loss: 2.4660 - val_accuracy: 0.6875\n","Epoch 272/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9839\n","Epoch 272: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0517 - accuracy: 0.9839 - val_loss: 2.3995 - val_accuracy: 0.6875\n","Epoch 273/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\n","Epoch 273: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.4312 - val_accuracy: 0.6875\n","Epoch 274/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000\n","Epoch 274: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.4619 - val_accuracy: 0.6875\n","Epoch 275/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000\n","Epoch 275: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.6875\n","Epoch 276/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000    \n","Epoch 276: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.6061 - val_accuracy: 0.6875\n","Epoch 277/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0313 - accuracy: 0.9821\n","Epoch 277: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9839 - val_loss: 2.6767 - val_accuracy: 0.6875\n","Epoch 278/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0340 - accuracy: 0.9821\n","Epoch 278: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0307 - accuracy: 0.9839 - val_loss: 2.7924 - val_accuracy: 0.6875\n","Epoch 279/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n","Epoch 279: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0381 - accuracy: 0.9839 - val_loss: 2.8814 - val_accuracy: 0.6875\n","Epoch 280/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n","Epoch 280: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.8471 - val_accuracy: 0.6875\n","Epoch 281/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9839\n","Epoch 281: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9839 - val_loss: 2.8083 - val_accuracy: 0.6875\n","Epoch 282/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000    \n","Epoch 282: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.6875\n","Epoch 283/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n","Epoch 283: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8086 - val_accuracy: 0.6875\n","Epoch 284/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0651 - accuracy: 0.9821\n","Epoch 284: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0603 - accuracy: 0.9839 - val_loss: 2.7642 - val_accuracy: 0.6875\n","Epoch 285/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0400 - accuracy: 0.9792\n","Epoch 285: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9839 - val_loss: 2.7279 - val_accuracy: 0.6875\n","Epoch 286/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0702 - accuracy: 0.9821\n","Epoch 286: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0636 - accuracy: 0.9839 - val_loss: 2.6441 - val_accuracy: 0.6250\n","Epoch 287/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000    \n","Epoch 287: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.6292 - val_accuracy: 0.6250\n","Epoch 288/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000    \n","Epoch 288: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.6986 - val_accuracy: 0.6250\n","Epoch 289/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n","Epoch 289: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7420 - val_accuracy: 0.6250\n","Epoch 290/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0249 - accuracy: 0.9821    \n","Epoch 290: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9839 - val_loss: 2.8010 - val_accuracy: 0.6250\n","Epoch 291/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0318 - accuracy: 0.9821\n","Epoch 291: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 0.9839 - val_loss: 2.8363 - val_accuracy: 0.6875\n","Epoch 292/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n","Epoch 292: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.6875\n","Epoch 293/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n","Epoch 293: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.8635 - val_accuracy: 0.6875\n","Epoch 294/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n","Epoch 294: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8995 - val_accuracy: 0.6875\n","Epoch 295/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 295: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 3.0276 - val_accuracy: 0.6875\n","Epoch 296/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n","Epoch 296: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 3.0638 - val_accuracy: 0.6875\n","Epoch 297/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0220 - accuracy: 0.9792    \n","Epoch 297: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 0.9839 - val_loss: 3.0431 - val_accuracy: 0.6875\n","Epoch 298/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000\n","Epoch 298: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9942 - val_accuracy: 0.6875\n","Epoch 299/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000\n","Epoch 299: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8846 - val_accuracy: 0.6875\n","Epoch 300/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000\n","Epoch 300: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.8077 - val_accuracy: 0.6875\n","Epoch 301/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n","Epoch 301: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7838 - val_accuracy: 0.6875\n","Epoch 302/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n","Epoch 302: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.6875\n","Epoch 303/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n","Epoch 303: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.8433 - val_accuracy: 0.6875\n","Epoch 304/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000\n","Epoch 304: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.9018 - val_accuracy: 0.6875\n","Epoch 305/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\n","Epoch 305: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0594 - val_accuracy: 0.6875\n","Epoch 306/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n","Epoch 306: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 3.1183 - val_accuracy: 0.6875\n","Epoch 307/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \n","Epoch 307: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1638 - val_accuracy: 0.6875\n","Epoch 308/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n","Epoch 308: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.1926 - val_accuracy: 0.6875\n","Epoch 309/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000    \n","Epoch 309: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 3.0451 - val_accuracy: 0.6875\n","Epoch 310/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n","Epoch 310: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8471 - val_accuracy: 0.6875\n","Epoch 311/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0292 - accuracy: 0.9821    \n","Epoch 311: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0502 - accuracy: 0.9677 - val_loss: 2.8163 - val_accuracy: 0.6875\n","Epoch 312/500\n","6/8 [=====================>........] - ETA: 0s - loss: 2.2066e-04 - accuracy: 1.0000\n","Epoch 312: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8510 - val_accuracy: 0.6875\n","Epoch 313/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000\n","Epoch 313: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8547 - val_accuracy: 0.6875\n","Epoch 314/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n","Epoch 314: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.8617 - val_accuracy: 0.6875\n","Epoch 315/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0105 - accuracy: 1.0000\n","Epoch 315: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8820 - val_accuracy: 0.6875\n","Epoch 316/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000    \n","Epoch 316: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.9168 - val_accuracy: 0.6875\n","Epoch 317/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9839\n","Epoch 317: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0321 - accuracy: 0.9839 - val_loss: 3.0275 - val_accuracy: 0.6875\n","Epoch 318/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0268 - accuracy: 0.9821    \n","Epoch 318: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9839 - val_loss: 3.0712 - val_accuracy: 0.6875\n","Epoch 319/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0229 - accuracy: 1.0000    \n","Epoch 319: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 3.1690 - val_accuracy: 0.6875\n","Epoch 320/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n","Epoch 320: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9839 - val_loss: 3.3695 - val_accuracy: 0.6875\n","Epoch 321/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0611 - accuracy: 0.9583\n","Epoch 321: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0559 - accuracy: 0.9677 - val_loss: 3.4331 - val_accuracy: 0.6875\n","Epoch 322/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0550 - accuracy: 0.9583\n","Epoch 322: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0428 - accuracy: 0.9677 - val_loss: 3.4335 - val_accuracy: 0.6875\n","Epoch 323/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0938 - accuracy: 0.9643\n","Epoch 323: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0939 - accuracy: 0.9677 - val_loss: 3.2008 - val_accuracy: 0.6250\n","Epoch 324/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000    \n","Epoch 324: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.3516 - val_accuracy: 0.6250\n","Epoch 325/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000    \n","Epoch 325: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.3986 - val_accuracy: 0.5625\n","Epoch 326/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000    \n","Epoch 326: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.3623 - val_accuracy: 0.5625\n","Epoch 327/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0349 - accuracy: 0.9792\n","Epoch 327: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0473 - accuracy: 0.9839 - val_loss: 3.3605 - val_accuracy: 0.5625\n","Epoch 328/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000    \n","Epoch 328: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.3826 - val_accuracy: 0.5625\n","Epoch 329/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000    \n","Epoch 329: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.4080 - val_accuracy: 0.5625\n","Epoch 330/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0422 - accuracy: 0.9792\n","Epoch 330: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0329 - accuracy: 0.9839 - val_loss: 3.2713 - val_accuracy: 0.5625\n","Epoch 331/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000    \n","Epoch 331: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.2222 - val_accuracy: 0.5625\n","Epoch 332/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 332: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 3.1989 - val_accuracy: 0.6250\n","Epoch 333/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 333: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 3.1965 - val_accuracy: 0.5625\n","Epoch 334/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0289 - accuracy: 1.0000\n","Epoch 334: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 3.1978 - val_accuracy: 0.6250\n","Epoch 335/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0346 - accuracy: 0.9750    \n","Epoch 335: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 0.9839 - val_loss: 3.2010 - val_accuracy: 0.6250\n","Epoch 336/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 336: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.2082 - val_accuracy: 0.6250\n","Epoch 337/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n","Epoch 337: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.2128 - val_accuracy: 0.6250\n","Epoch 338/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000    \n","Epoch 338: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 3.2105 - val_accuracy: 0.6250\n","Epoch 339/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n","Epoch 339: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 3.2410 - val_accuracy: 0.6250\n","Epoch 340/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\n","Epoch 340: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 3.2617 - val_accuracy: 0.6250\n","Epoch 341/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000    \n","Epoch 341: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 3.2591 - val_accuracy: 0.6250\n","Epoch 342/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n","Epoch 342: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 3.2969 - val_accuracy: 0.6250\n","Epoch 343/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000\n","Epoch 343: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 3.5529 - val_accuracy: 0.6250\n","Epoch 344/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n","Epoch 344: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.8630 - val_accuracy: 0.6250\n","Epoch 345/500\n","6/8 [=====================>........] - ETA: 0s - loss: 4.9585e-04 - accuracy: 1.0000\n","Epoch 345: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.0006 - val_accuracy: 0.6250\n","Epoch 346/500\n","7/8 [=========================>....] - ETA: 0s - loss: 8.1923e-04 - accuracy: 1.0000\n","Epoch 346: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.0640 - val_accuracy: 0.6250\n","Epoch 347/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0335 - accuracy: 0.9821    \n","Epoch 347: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9839 - val_loss: 4.0736 - val_accuracy: 0.6250\n","Epoch 348/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000    \n","Epoch 348: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.0691 - val_accuracy: 0.6250\n","Epoch 349/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 349: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 4.0825 - val_accuracy: 0.6250\n","Epoch 350/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0571 - accuracy: 0.9792\n","Epoch 350: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0674 - accuracy: 0.9677 - val_loss: 4.0959 - val_accuracy: 0.6250\n","Epoch 351/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0499 - accuracy: 0.9643    \n","Epoch 351: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0451 - accuracy: 0.9677 - val_loss: 4.0418 - val_accuracy: 0.6250\n","Epoch 352/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n","Epoch 352: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.9948 - val_accuracy: 0.6250\n","Epoch 353/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n","Epoch 353: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.9790 - val_accuracy: 0.6250\n","Epoch 354/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0660 - accuracy: 0.9583\n","Epoch 354: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.9677 - val_loss: 3.9685 - val_accuracy: 0.6250\n","Epoch 355/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n","Epoch 355: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.8910 - val_accuracy: 0.6250\n","Epoch 356/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0372 - accuracy: 0.9821    \n","Epoch 356: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9839 - val_loss: 3.8510 - val_accuracy: 0.6250\n","Epoch 357/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n","Epoch 357: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.8377 - val_accuracy: 0.6250\n","Epoch 358/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000    \n","Epoch 358: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.8476 - val_accuracy: 0.6250\n","Epoch 359/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\n","Epoch 359: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.8399 - val_accuracy: 0.6250\n","Epoch 360/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000    \n","Epoch 360: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.8207 - val_accuracy: 0.6250\n","Epoch 361/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n","Epoch 361: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 3.7541 - val_accuracy: 0.6250\n","Epoch 362/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n","Epoch 362: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.7216 - val_accuracy: 0.6250\n","Epoch 363/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n","Epoch 363: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.7233 - val_accuracy: 0.6250\n","Epoch 364/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0442 - accuracy: 0.9792    \n","Epoch 364: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0381 - accuracy: 0.9839 - val_loss: 3.7324 - val_accuracy: 0.6250\n","Epoch 365/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n","Epoch 365: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 3.7396 - val_accuracy: 0.6250\n","Epoch 366/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n","Epoch 366: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 3.8376 - val_accuracy: 0.6250\n","Epoch 367/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1076 - accuracy: 0.9464\n","Epoch 367: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.1069 - accuracy: 0.9516 - val_loss: 3.9377 - val_accuracy: 0.6250\n","Epoch 368/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0646 - accuracy: 0.9750\n","Epoch 368: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0427 - accuracy: 0.9839 - val_loss: 4.1260 - val_accuracy: 0.6250\n","Epoch 369/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0329 - accuracy: 0.9750    \n","Epoch 369: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 18ms/step - loss: 0.0229 - accuracy: 0.9839 - val_loss: 4.2197 - val_accuracy: 0.6250\n","Epoch 370/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n","Epoch 370: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 18ms/step - loss: 0.0227 - accuracy: 0.9839 - val_loss: 4.2416 - val_accuracy: 0.6250\n","Epoch 371/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000    \n","Epoch 371: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 20ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.2691 - val_accuracy: 0.6250\n","Epoch 372/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n","Epoch 372: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.2445 - val_accuracy: 0.6250\n","Epoch 373/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n","Epoch 373: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.2368 - val_accuracy: 0.6250\n","Epoch 374/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0231 - accuracy: 0.9821\n","Epoch 374: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9839 - val_loss: 4.1713 - val_accuracy: 0.6250\n","Epoch 375/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000    \n","Epoch 375: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1288 - val_accuracy: 0.6250\n","Epoch 376/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0210 - accuracy: 0.9792\n","Epoch 376: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0694 - accuracy: 0.9516 - val_loss: 3.8484 - val_accuracy: 0.6250\n","Epoch 377/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0402 - accuracy: 0.9792    \n","Epoch 377: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9839 - val_loss: 3.7082 - val_accuracy: 0.6250\n","Epoch 378/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0226 - accuracy: 0.9792    \n","Epoch 378: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 0.9839 - val_loss: 3.6306 - val_accuracy: 0.6250\n","Epoch 379/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000    \n","Epoch 379: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 3.5877 - val_accuracy: 0.6250\n","Epoch 380/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 380: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6328 - val_accuracy: 0.6250\n","Epoch 381/500\n","7/8 [=========================>....] - ETA: 0s - loss: 9.1804e-04 - accuracy: 1.0000\n","Epoch 381: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.6656 - val_accuracy: 0.6250\n","Epoch 382/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000    \n","Epoch 382: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 3.7933 - val_accuracy: 0.6250\n","Epoch 383/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n","Epoch 383: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9839 - val_loss: 3.7826 - val_accuracy: 0.6250\n","Epoch 384/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n","Epoch 384: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.5292 - val_accuracy: 0.6250\n","Epoch 385/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000    \n","Epoch 385: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.4719 - val_accuracy: 0.6250\n","Epoch 386/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000    \n","Epoch 386: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.4451 - val_accuracy: 0.6250\n","Epoch 387/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0442 - accuracy: 0.9643    \n","Epoch 387: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0403 - accuracy: 0.9677 - val_loss: 3.4356 - val_accuracy: 0.6250\n","Epoch 388/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0247 - accuracy: 0.9821\n","Epoch 388: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9839 - val_loss: 3.4008 - val_accuracy: 0.6250\n","Epoch 389/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 389: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.4766 - val_accuracy: 0.7500\n","Epoch 390/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n","Epoch 390: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.6014 - val_accuracy: 0.7500\n","Epoch 391/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n","Epoch 391: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 3.7111 - val_accuracy: 0.6875\n","Epoch 392/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0408 - accuracy: 0.9792\n","Epoch 392: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0317 - accuracy: 0.9839 - val_loss: 3.8176 - val_accuracy: 0.6250\n","Epoch 393/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9643    \n","Epoch 393: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0458 - accuracy: 0.9677 - val_loss: 4.0464 - val_accuracy: 0.6250\n","Epoch 394/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0505 - accuracy: 0.9750    \n","Epoch 394: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0616 - accuracy: 0.9677 - val_loss: 4.2724 - val_accuracy: 0.6250\n","Epoch 395/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000    \n","Epoch 395: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 4.3493 - val_accuracy: 0.6250\n","Epoch 396/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n","Epoch 396: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 4.3778 - val_accuracy: 0.6250\n","Epoch 397/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0342 - accuracy: 0.9792\n","Epoch 397: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.9839 - val_loss: 4.3805 - val_accuracy: 0.6250\n","Epoch 398/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n","Epoch 398: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.3470 - val_accuracy: 0.6250\n","Epoch 399/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000    \n","Epoch 399: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.3359 - val_accuracy: 0.6250\n","Epoch 400/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0753 - accuracy: 0.9792\n","Epoch 400: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0583 - accuracy: 0.9839 - val_loss: 4.4573 - val_accuracy: 0.6250\n","Epoch 401/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0103 - accuracy: 1.0000\n","Epoch 401: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0320 - accuracy: 0.9839 - val_loss: 4.5108 - val_accuracy: 0.6250\n","Epoch 402/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0638 - accuracy: 0.9792\n","Epoch 402: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0494 - accuracy: 0.9839 - val_loss: 4.5865 - val_accuracy: 0.6250\n","Epoch 403/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n","Epoch 403: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.6758 - val_accuracy: 0.6250\n","Epoch 404/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0329 - accuracy: 0.9821\n","Epoch 404: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.9839 - val_loss: 4.7061 - val_accuracy: 0.6250\n","Epoch 405/500\n","7/8 [=========================>....] - ETA: 0s - loss: 4.0569e-04 - accuracy: 1.0000\n","Epoch 405: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 4.0078e-04 - accuracy: 1.0000 - val_loss: 4.7189 - val_accuracy: 0.6250\n","Epoch 406/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 406: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.7110 - val_accuracy: 0.6250\n","Epoch 407/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0429 - accuracy: 0.9792\n","Epoch 407: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 18ms/step - loss: 0.0333 - accuracy: 0.9839 - val_loss: 4.5492 - val_accuracy: 0.6250\n","Epoch 408/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0560 - accuracy: 0.9792\n","Epoch 408: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 4.6378 - val_accuracy: 0.6250\n","Epoch 409/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 409: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7083 - val_accuracy: 0.6250\n","Epoch 410/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000\n","Epoch 410: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 4.7592 - val_accuracy: 0.6250\n","Epoch 411/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0475 - accuracy: 0.9792    \n","Epoch 411: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9839 - val_loss: 4.7125 - val_accuracy: 0.6250\n","Epoch 412/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n","Epoch 412: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.6611 - val_accuracy: 0.6250\n","Epoch 413/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000    \n","Epoch 413: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.6606 - val_accuracy: 0.6250\n","Epoch 414/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000    \n","Epoch 414: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.6966 - val_accuracy: 0.6250\n","Epoch 415/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0380 - accuracy: 0.9821    \n","Epoch 415: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0344 - accuracy: 0.9839 - val_loss: 4.7586 - val_accuracy: 0.6250\n","Epoch 416/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n","Epoch 416: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.8089 - val_accuracy: 0.6250\n","Epoch 417/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0258 - accuracy: 0.9821\n","Epoch 417: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 0.9839 - val_loss: 4.8909 - val_accuracy: 0.6250\n","Epoch 418/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n","Epoch 418: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 4.9078 - val_accuracy: 0.6250\n","Epoch 419/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0309 - accuracy: 0.9792\n","Epoch 419: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 0.9839 - val_loss: 4.9155 - val_accuracy: 0.6250\n","Epoch 420/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0224 - accuracy: 0.9821    \n","Epoch 420: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0204 - accuracy: 0.9839 - val_loss: 4.9219 - val_accuracy: 0.6250\n","Epoch 421/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0285 - accuracy: 0.9792    \n","Epoch 421: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0361 - accuracy: 0.9677 - val_loss: 5.0279 - val_accuracy: 0.6250\n","Epoch 422/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000    \n","Epoch 422: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 5.0704 - val_accuracy: 0.6250\n","Epoch 423/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000\n","Epoch 423: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 5.1530 - val_accuracy: 0.6250\n","Epoch 424/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n","Epoch 424: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.1850 - val_accuracy: 0.6250\n","Epoch 425/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n","Epoch 425: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.1807 - val_accuracy: 0.6250\n","Epoch 426/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9821\n","Epoch 426: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0481 - accuracy: 0.9839 - val_loss: 4.9206 - val_accuracy: 0.6250\n","Epoch 427/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n","Epoch 427: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.4780 - val_accuracy: 0.6250\n","Epoch 428/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000    \n","Epoch 428: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 4.5839 - val_accuracy: 0.5625\n","Epoch 429/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n","Epoch 429: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 6.5741 - val_accuracy: 0.5625\n","Epoch 430/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n","Epoch 430: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 7.1247 - val_accuracy: 0.5625\n","Epoch 431/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0874 - accuracy: 0.9792\n","Epoch 431: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0678 - accuracy: 0.9839 - val_loss: 3.8460 - val_accuracy: 0.6875\n","Epoch 432/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n","Epoch 432: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.9060 - val_accuracy: 0.6875\n","Epoch 433/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0416 - accuracy: 0.9792    \n","Epoch 433: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.3158 - accuracy: 0.9516 - val_loss: 2.7002 - val_accuracy: 0.7500\n","Epoch 434/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4766 - accuracy: 0.9286\n","Epoch 434: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.4305 - accuracy: 0.9355 - val_loss: 4.1602 - val_accuracy: 0.6875\n","Epoch 435/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2026 - accuracy: 0.9464\n","Epoch 435: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.1830 - accuracy: 0.9516 - val_loss: 3.5436 - val_accuracy: 0.6875\n","Epoch 436/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000\n","Epoch 436: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0499 - accuracy: 0.9839 - val_loss: 3.3194 - val_accuracy: 0.6875\n","Epoch 437/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9286\n","Epoch 437: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.2953 - accuracy: 0.9355 - val_loss: 3.4610 - val_accuracy: 0.6250\n","Epoch 438/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000\n","Epoch 438: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.7628 - val_accuracy: 0.6875\n","Epoch 439/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\n","Epoch 439: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 3.6268 - val_accuracy: 0.6875\n","Epoch 440/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0294 - accuracy: 0.9792\n","Epoch 440: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0431 - accuracy: 0.9677 - val_loss: 2.9958 - val_accuracy: 0.6875\n","Epoch 441/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0695 - accuracy: 0.9583\n","Epoch 441: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0635 - accuracy: 0.9677 - val_loss: 2.5729 - val_accuracy: 0.6875\n","Epoch 442/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0699 - accuracy: 0.9583\n","Epoch 442: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0701 - accuracy: 0.9516 - val_loss: 2.3514 - val_accuracy: 0.6875\n","Epoch 443/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0593 - accuracy: 0.9643\n","Epoch 443: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0537 - accuracy: 0.9677 - val_loss: 2.5278 - val_accuracy: 0.6875\n","Epoch 444/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0614 - accuracy: 0.9750\n","Epoch 444: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0448 - accuracy: 0.9839 - val_loss: 2.6091 - val_accuracy: 0.7500\n","Epoch 445/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000\n","Epoch 445: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.6969 - val_accuracy: 0.7500\n","Epoch 446/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000    \n","Epoch 446: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0353 - accuracy: 0.9839 - val_loss: 2.7128 - val_accuracy: 0.7500\n","Epoch 447/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n","Epoch 447: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.7164 - val_accuracy: 0.7500\n","Epoch 448/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n","Epoch 448: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.7226 - val_accuracy: 0.7500\n","Epoch 449/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0403 - accuracy: 0.9792\n","Epoch 449: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9839 - val_loss: 2.7613 - val_accuracy: 0.6875\n","Epoch 450/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000\n","Epoch 450: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.6875\n","Epoch 451/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n","Epoch 451: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.8165 - val_accuracy: 0.6875\n","Epoch 452/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000    \n","Epoch 452: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.8073 - val_accuracy: 0.6875\n","Epoch 453/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0201 - accuracy: 1.0000\n","Epoch 453: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8669 - val_accuracy: 0.6875\n","Epoch 454/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 454: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.9133 - val_accuracy: 0.6875\n","Epoch 455/500\n","8/8 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\n","Epoch 455: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.9416 - val_accuracy: 0.6875\n","Epoch 456/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000    \n","Epoch 456: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.9586 - val_accuracy: 0.6875\n","Epoch 457/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0742 - accuracy: 0.9792\n","Epoch 457: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.1033 - accuracy: 0.9677 - val_loss: 2.9461 - val_accuracy: 0.6875\n","Epoch 458/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 458: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.8981 - val_accuracy: 0.6875\n","Epoch 459/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0168 - accuracy: 1.0000\n","Epoch 459: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.8622 - val_accuracy: 0.6875\n","Epoch 460/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0508 - accuracy: 0.9821\n","Epoch 460: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 2.8866 - val_accuracy: 0.6875\n","Epoch 461/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000    \n","Epoch 461: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0184 - val_accuracy: 0.6875\n","Epoch 462/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0188 - accuracy: 0.9821\n","Epoch 462: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9839 - val_loss: 3.0947 - val_accuracy: 0.6875\n","Epoch 463/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0362 - accuracy: 0.9821\n","Epoch 463: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0377 - accuracy: 0.9839 - val_loss: 3.1119 - val_accuracy: 0.6875\n","Epoch 464/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0319 - accuracy: 0.9821    \n","Epoch 464: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0392 - accuracy: 0.9839 - val_loss: 3.0863 - val_accuracy: 0.6875\n","Epoch 465/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 465: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.0338 - val_accuracy: 0.6875\n","Epoch 466/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9821\n","Epoch 466: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0422 - accuracy: 0.9839 - val_loss: 2.9226 - val_accuracy: 0.6875\n","Epoch 467/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n","Epoch 467: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.8942 - val_accuracy: 0.6875\n","Epoch 468/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000    \n","Epoch 468: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.8856 - val_accuracy: 0.6875\n","Epoch 469/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0347 - accuracy: 0.9792\n","Epoch 469: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 0.9839 - val_loss: 2.9247 - val_accuracy: 0.6875\n","Epoch 470/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n","Epoch 470: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9452 - val_accuracy: 0.6875\n","Epoch 471/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n","Epoch 471: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.9656 - val_accuracy: 0.7500\n","Epoch 472/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0255 - accuracy: 0.9821\n","Epoch 472: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 0.9839 - val_loss: 2.9315 - val_accuracy: 0.7500\n","Epoch 473/500\n","6/8 [=====================>........] - ETA: 0s - loss: 6.8475e-04 - accuracy: 1.0000\n","Epoch 473: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.9075 - val_accuracy: 0.7500\n","Epoch 474/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0354 - accuracy: 0.9821    \n","Epoch 474: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 0.9839 - val_loss: 2.9138 - val_accuracy: 0.7500\n","Epoch 475/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000\n","Epoch 475: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0394 - accuracy: 0.9839 - val_loss: 2.9217 - val_accuracy: 0.7500\n","Epoch 476/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n","Epoch 476: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9302 - val_accuracy: 0.7500\n","Epoch 477/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000    \n","Epoch 477: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9267 - val_accuracy: 0.7500\n","Epoch 478/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0240 - accuracy: 0.9821    \n","Epoch 478: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9839 - val_loss: 2.8298 - val_accuracy: 0.7500\n","Epoch 479/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000    \n","Epoch 479: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.7500\n","Epoch 480/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000\n","Epoch 480: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.7500\n","Epoch 481/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n","Epoch 481: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8040 - val_accuracy: 0.7500\n","Epoch 482/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n","Epoch 482: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0248 - accuracy: 0.9839 - val_loss: 2.8339 - val_accuracy: 0.7500\n","Epoch 483/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n","Epoch 483: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.8455 - val_accuracy: 0.7500\n","Epoch 484/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000    \n","Epoch 484: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.8605 - val_accuracy: 0.7500\n","Epoch 485/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000    \n","Epoch 485: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8724 - val_accuracy: 0.7500\n","Epoch 486/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n","Epoch 486: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.7500\n","Epoch 487/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0270 - accuracy: 1.0000\n","Epoch 487: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 2.9125 - val_accuracy: 0.7500\n","Epoch 488/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000    \n","Epoch 488: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.9320 - val_accuracy: 0.7500\n","Epoch 489/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0344 - accuracy: 1.0000\n","Epoch 489: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 2.9965 - val_accuracy: 0.7500\n","Epoch 490/500\n","5/8 [=================>............] - ETA: 0s - loss: 0.0186 - accuracy: 1.0000\n","Epoch 490: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 3.0429 - val_accuracy: 0.7500\n","Epoch 491/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    \n","Epoch 491: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0663 - val_accuracy: 0.7500\n","Epoch 492/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000    \n","Epoch 492: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0471 - accuracy: 0.9839 - val_loss: 3.1276 - val_accuracy: 0.7500\n","Epoch 493/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 493: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 3.1741 - val_accuracy: 0.7500\n","Epoch 494/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n","Epoch 494: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.2460 - val_accuracy: 0.7500\n","Epoch 495/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0396 - accuracy: 0.9792\n","Epoch 495: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0727 - accuracy: 0.9677 - val_loss: 3.5720 - val_accuracy: 0.7500\n","Epoch 496/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n","Epoch 496: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0598 - accuracy: 0.9839 - val_loss: 3.7664 - val_accuracy: 0.7500\n","Epoch 497/500\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000    \n","Epoch 497: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.7706 - val_accuracy: 0.7500\n","Epoch 498/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n","Epoch 498: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.7860 - val_accuracy: 0.7500\n","Epoch 499/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n","Epoch 499: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.7902 - val_accuracy: 0.7500\n","Epoch 500/500\n","6/8 [=====================>........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000    \n","Epoch 500: val_accuracy did not improve from 0.87500\n","8/8 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.8062 - val_accuracy: 0.7500\n"]}],"source":["epochs = 500\n","history=model.fit(X_train, y_train, batch_size=8, epochs=epochs,validation_data=(X_test,y_test) , callbacks = callback_list)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"XvOTMmEKsSjj","executionInfo":{"status":"ok","timestamp":1652598277889,"user_tz":-330,"elapsed":721,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["import pickle\n","\n","# to save the fitted tokenizer\n","with open('/content/drive/MyDrive/LSTM/tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    \n","# to save the fitted label encoder\n","with open('/content/drive/MyDrive/LSTM/label_encoder.pickle', 'wb') as ecn_file:\n","    pickle.dump(onehot_encoded, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"dqozThSxIKxd"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"HKOs3W9LvI-V","executionInfo":{"status":"ok","timestamp":1652598277891,"user_tz":-330,"elapsed":7,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[],"source":["from tensorflow import keras\n","import random\n","import numpy as np"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucygrd6xtJsg","outputId":"d8c71aab-eb0d-4fca-ae8d-f546c3be83a1","executionInfo":{"status":"ok","timestamp":1652598345962,"user_tz":-330,"elapsed":68077,"user":{"displayName":"PUNGLIYA VITHIKA","userId":"10245521390697241014"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Hi\n","ChatBot: Hi there\n","What is TRF?\n","ChatBot: The Robotics Forum is VIT Pune's premier robotics club, with a 15-year legacy. Students from various engineering disciplines make up our varied community, all of whom are driven by a passion for robotics. The goal of the team is to gain new skills, explore new technologies, and promote the area of robotics.\n","How can I join TRF?\n","ChatBot: \n","Every year TRF conducts its recruitment process around the end of academic year. This process is for Mechanical , Electrical , Programming as well as the Admin team. The details about the entire process is informed well before the registration and ample preparation time is provided to the students,. \n","Thank You!\n","ChatBot: Have a nice day\n","quit\n"]}],"source":["def chat():\n","    # load trained model\n","    chat_model = keras.models.load_model('/content/drive/MyDrive/LSTM/bestv3.h5')\n","\n","    # load tokenizer object\n","    with open('/content/drive/MyDrive/LSTM/tokenizer.pickle', 'rb') as handle:\n","        tokenizer = pickle.load(handle)\n","\n","    # load label encoder object\n","    with open('/content/drive/MyDrive/LSTM/label_encoder.pickle', 'rb') as enc:\n","        onehot_encoded = pickle.load(enc)\n","\n","    # parameters\n","    max_len = 10\n","    \n","    while True:\n","        \n","        inp = input()\n","        if inp.lower() == \"quit\":\n","            break\n","\n","        result = chat_model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n","                                             truncating='post', maxlen=max_len))\n","        tag = label_encoder.inverse_transform([np.argmax(result)])\n","        \n","\n","        for i in data['intents']:\n","            if i['tag'] == tag:\n","                print(\"ChatBot:\", np.random.choice(i['responses']))\n","chat()"]}],"metadata":{"colab":{"name":"chatbot_LSTM.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}